---
title: "Stat 230 HW 3"
author: "Name: Teagan Johnson"
output: pdf_document
---
```{r, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, prompt=TRUE, comment=NULL)
```


### worked with: Alex Widman and Miles Tisserand


Homework 3 is due **by 3pm Monday, Oct. 4**. Please complete the assignment in this Markdown document, filling in your answers and R code below.  I didn't create answer and R chunk fields like I did with homework 1, but please fill in your answers and R code in the same manner as hw 1.  Submit  a hard copy of the **compiled pdf or word doc** either

  - in class on Monday 9/20
  - in drop-in office hours (Tuesday 9/21)
  - in the paper holder outside my CMC 222 office door (hopefully it will be installed by then!)

Tips for using Markdown with homework sets:

- Work through a problem by putting your R code into R chunks in this .Rmd. Run the R code to make sure it works, then knit the .Rmd to verify they work in that environment. 
    - Make sure you load your data in the .Rmd and include any needed `library` commands. 
- Feel free to edit or delete  questions, instructions, or code provided in this file when producing your homework solution. 
- For your final document, you can change the output type from `html_document` to `word_document` or `pdf_document`. These two to output types are better formatted for printing. 
  - on maize: you may need to allow for pop-ups from this site 
- If you want to knit to pdf while running Rstudio from your computer (*not* from maize), you  will need a LaTeX compiler installed on your computer. This could be [MiKTeX](https://miktex.org/), [MacTeX](http://www.tug.org/mactex/) (mac), or TinyTex. The latter is installed in R: first install the R package `tinytex`, then run the command `tinytex::install_tinytex()` to install this software. 
  - If you are using maize, you don't need to install anything to knit to pdf!


-------------------------------------


## Problem 1: Election Fraud: ch. 8 exercise 20 (a-c)

#### 8(a) Draw a scatterplot of Democratic percentage of absentee ballots versus Democratic percentage of machine-counted ballots. Use a separate plotting symbol to highlight the disputed election.
\
*Answer: *\
Look at scatterplot below. The red disputed election seems to be an outlier.


```{r}
library(Sleuth3)
head(ex0820)
```

```{r}
library(ggplot2)
library(dplyr)
ggplot(ex0820, aes(x=DemPctOfMachineVotes, y=DemPctOfAbsenteeVotes)) + geom_point() + geom_point(data=filter(ex0820, Disputed == "yes"), color="red") + labs(x="Democratic % of Machine Votes", y="Democratic % of Absentee Votes", title="Dem % of Machine Votes vs. Dem % of Absentee Votes")
```
  
#### 8(b) Fit the simple linear regression of absentee percentage on machine-count percentage, excluding the disputed election. Draw this line on the scatterplot. Also include a 95% prediction band. What does this plot reveal about the unusualness of the absentee percentage in the disputed election?\

*Answer: *\
This plot, excluding the outlier (as the question asked), shows that most elections are within the 95% confidence interval. However, the outlier is extremely far away from the 95% confidence interval. This suppots the idea that the number of absentee ballots in the disputed election were significantly higher than should be expected.

```{r}
voting_lm <- lm(DemPctOfAbsenteeVotes ~ DemPctOfMachineVotes, data=ex0820)

which(ex0820$Disputed == "yes")

voting_no_outliers <- ex0820[-c(22), ]

voting_lm_no_outliers <- lm(DemPctOfAbsenteeVotes ~ DemPctOfMachineVotes, data=voting_no_outliers)

voting_data_pred <- data.frame(voting_no_outliers, predict(voting_lm_no_outliers, interval = "prediction"))

normal_elections <- filter(ex0820, Disputed == "no")

ggplot(
  voting_data_pred, aes(x=DemPctOfMachineVotes, y=DemPctOfAbsenteeVotes)) + 
  geom_point() + 
  geom_smooth(method="lm") + 
  labs(x="Democratic % of Machine Votes", y="Democratic % of Absentee Votes", title="Dem % of Machine Votes vs. Dem % of Absentee Votes") + 
  geom_ribbon(
    aes(ymin = lwr,
        ymax = upr,
        fill = "prediction"),
    alpha = .1)
  
```
  
#### 8(c) Find the prediction and standard error of prediction from this fit if the machine-count percentage is 49.3 (as it is for the disputed election). How many estimated standard deviations is the observed absentee percentage, 79.0, from this predicted value? Compare this answer to a t-distribution (with degrees of freedom equal to the residual degrees of freedom in the regression fit) to obtain a p-value.
\
*Answer: *\
The predicted percentage of absentee votes given a machine coune percentage of 49.3% is 50.873%. The standard error of prediction from this fit is 10.457. Using the formula $SE(pred_{x|y=49.3}) = \sqrt{\sigma^2 + (SE(\mu)^2)}$ and using the se.fit value for $SE(\mu)$ and the residual_scale value for $\sigma^2$.\
The predicted value of 50.873% is 4.057263207 standard deviations away from the mean. This was calculated using $(observed) - (expected) / standarderror$ or $(79-50.873)/10.457$.\
Using the pt() command, and plugging in 4.057263207 for the standard deviations and 19 for the degrees of freedom, we get a p-value of 0.0003361276. This is statistically significant and provides evidence to reject the idea that the disputed election was just a chance occurence.

```{r}
library(broom)
predict(voting_lm,
        newdata = data.frame(DemPctOfMachineVotes = 49.3),
        interval = "prediction",
        se.fit=T)
pt(-4.057263207, 19)
```
  
- For part (b), add the regression line and prediction bands from (b) to the plot created in (a).
- The data for this problem is `ex0820`
- for (a): To highlight the disputed election in your `ggplot`, add the layer `geom_point(data=filter(ex0820, Disputed == "yes"), color="red")` using the `filter` command from the `dplyr` package. You can even play with the `size` argument in `geom_point` to increase the size so the point stands out when printed in black and white.

-------------------------------------


## Problem 2: Island Area and Species
Consider Conceptual Exercise 1 (pg.227) in chapter 8. (Its solution is at the end of the chapter.) They show in this example that a halving of area  is associated with a 16% reduction in median number of species. What happens if we double area? Show all work, be specific (give an amount of change, explain  what is changing (median? mean?), and explain your answer in context. Make sure to explain your answer in terms of the original scale of the variables (not on the log scale).\

*Answer: *\
Doubling the area is associated with a multiplicative increase of 1.189 in estimated median of the number of species. See calculation below:\
$median(species|area) = e^{1.94} * area^.25$\
$median(species|2area) = e^{1.94} * (2area)^.25$\
$\frac{median(species|area)}{median(species|2area)} = \frac{(2area)^.25}{area^.25}$
$\frac{1.189area}{area}$
$|1-1.189| = .189$\

This means that if we double the area, the number of species in that space will increase by a factor of 1.189.

-------------------------------------


## Problem 3: Pollution
The data set `Pcb.csv` contains information on PCB (a hazardous industrial chemical) levels (ppm, parts per million) in various bodies of water for the years 1984 and 1985. Researchers would like to understand how levels of the pollutant varies from year to year. We will consider how to build a model for 1985 PCB levels based on the 1984 levels.

```{r}
pcb <- read.csv("http://math.carleton.edu/kstclair/data/Pcb.csv")
head(pcb)
```


### (3a) 
Plot `pcb85` against `pcb84`. Notice the obvious outlier. Identify this point by site name and row number. Redraw this plot without the outlier. Explain why a SLR model is not appropriate for this data even with the outlier removed.
\
*Answer: *\
The row number is row 4. The site name is Boston Harbor. This data is not fit for an SLR model because the variance is not constant. Looking at the residual plot, it is clear that there are many more points on the left side of the plot than the right side. Also, as x gets larger, the scatter becomes much more spread out. This indicates that the constant variance assumption and the linearity assumption are violated, proving that an SLR model is not appropiate for this data.

```{r}
library(ggResidpanel)
which(pcb$pcb84 > 3000)

pcb_no_outliers <- pcb[-c(4), ]

ggplot(data = pcb_no_outliers, aes(x = pcb84, y = pcb85)) + geom_point()

chemical_lm <- lm(pcb_no_outliers$pcb85 ~ pcb_no_outliers$pcb84, pcb_no_outliers)

resid_xpanel(chemical_lm)
```

### (3b)  
Plot log of `pcb8` against log of `pcb84` (including the outlier from (a)). Explain why we could fit a SLR model to the logged versions of pcb.
\
*Answer: *\
The plot of the log of pcb84 and pcb85 are much closer to following a linear model. Most points are close to the linear regression line. This satisfies the linearity assumption. Also, there is a relatively constant spread of points along the x axis. Therefore, the constant variance assumption is met (there is not a dependence on x for the points). There are, however, two outliers.

```{r}
ggplot(data = pcb, aes(x = pcb84, y = pcb85)) + 
  geom_point() + 
  scale_x_log10() + 
  scale_y_log10() + 
  labs(x = "log(pcb84)", y = "log(pcb85)") + 
  geom_smooth(method = "lm", se = FALSE)

#chemical_lm_log <- lm(log(pcb85) ~ log(pcb84), pcb)

#resid_xpanel(chemical_lm_log)
```

### (3c) 
Look at the values in the vector `log(pcb$pch85)`. Why are some values equal to `-Inf`? Give the names of the  sites that contain no pcb in 1984 and 1985, then create a subsetted data set that excludes these sites. Use this new subsetted data set to complete parts (d) below.

Hint: you can use the `filter` command with the filtering arguments equal to `pcb84 > 0,  pcb85 >0`. You can similarly use filter to find the "0" pcb cases, but be sure to use `pch84 == 0` to ask which cases are equal to (`==`) 0. 
\
*Answer: *\
Some of the values are -Infinity because the original pcb levels in those years are 0. In order to get 0, you have to raise the base number by the smallest number possible, which is -Infinity. The sites are Pamilico Sound, Sapelo Sound, Tampa Bay, Mobile Bay, Round Island, Barataria Bay, San Antonio Bay, and Corpus Christi Bay.

```{r}
pcb
all_zeroes <- which(log(pcb$pcb85) == -Inf)
all_zeroes <- c(all_zeroes)
pcb[, , all_zeroes]

pcb_no_zero <- filter(pcb, pcb84 > 0, pcb85 > 0)

pcb_zero <- filter(pcb, pcb84==0, pcb85==0)
```


### (3d) 
With the subsetted data `pcb_nonzero` from (c), fit the regression of log of pcb in 1985 on the log of pcb in 1984. Check and comment on model assumptions and identify two obvious outliers (by site name and row number from `pcb_nonzero`).
\
*Answer: *\
Rows 10 and 4 have the two obvious outliers. These rows are the Deleware Bay and the Boston Harbor. The linear assumption is not met Towards the left side of the graph, there appear to be more points under the resiudual line while on the right, there are more points above the residual line. The constant variance assumption is met when disregarding the outliers. There is no dependence on the x values to determine the number of points along the residual plot.

```{r}
ggplot(data = pcb_no_zero, aes(x = pcb84, y = pcb85)) + 
  geom_point() + 
  scale_x_log10() + 
  scale_y_log10()
which(pcb_no_zero$pcb84 < 10 & pcb_no_zero$pcb85 > 100)
which(pcb_no_zero$pcb84 > 5000)
pcb_no_zero[10,]
pcb_no_zero[4,]

lm_chemicals_no_zero <- lm(log(pcb85) ~ log(pcb84), pcb_no_zero)
resid_xpanel(lm_chemicals_no_zero)
```

### (3e) 
Create one more data frame, `pcb_nonzero2` that removes these two outliers. Then use this data to refit the model from (d) without the two outliers, verify that the residual plot looks better than in (d) and explain how they influence the estimated model slope and R-squared value. 
\
*Answer: *\
There is a similar scatter of points between above the residual line and below the data frame across the entire residual plot. Also, the number of points does not depend on the x value. Therefore, the linearity and constant variance assumptions are met. The outliers decrease the R-squared value. The outliers also increase the estimated slope.

```{r}
pcb_nonzero2 <- pcb_no_zero[-c(4, 10), ]
lm_chemicals_no_zero2 <- lm(log(pcb85) ~ log(pcb84), pcb_nonzero2)
resid_xpanel(lm_chemicals_no_zero2)

summary(lm_chemicals_no_zero)
summary(lm_chemicals_no_zero2)
```


### (3f)  
Using the estimated model from (e) without the two outliers, interpret the slope of the equation and R-squared, in context. Make sure to interpret the slope effect on the original scale of both variables.
\
*Answer: *\
The estimated intercept is .0925. The estimated slope is .95983. A 1 unit increase in x is associated with a multiplicative increase of $e^{0.9598}$ or 2.611. The regression of pcb in 1985 on the pcb in 1984 helps explain about 97.32% of the observed variation in the pcb levels in 1985.

-------------------------------------


## Problem 4:  Mammal Brain Weights
Consider Conceptual Exercise 4 (pg.261) in chapter 9. Note that they use the natural log [base-e] for each variable in this model:
$$
\hat{\mu}(\log(brainwt) \mid x)= 0.8548  + 0.5751\log(bodywt) + 0.4179 \log(gest) - 0.3101 \log(litter)
$$

### (4a) 
Write down the expression for the (mean? median?) brain weight given body weight, gestation, and litter. Show all work and simplify as much as possible. 
\
*Answer: *\
$\hat{\mu}(\log(brainwt) \mid x)= 0.8548  + 0.5751\log(bodywt) + 0.4179 \log(gest) - 0.3101 \log(litter)$\

### (4b) 
Interpret, in context and on the original scale, the effect of body size on brain weight. As usual, show all work and be specific  - give an amount of the effect and be careful about what is changing (median? mean?). Make sure to explain your answer in terms of the original scale of the variables (not on the log scale). Show all work. 
\
*Answer: *\
Doubling body weight is associated with an estimated $2^{0.5751}$ multiplicative increase (or a 48.97% increase) in the median brain weight of animals.\

$\hat{\mu}(\log(brainwt) \mid x)= 0.8548  + 0.5751\log(bodywt) + 0.4179 \log(gest) - 0.3101 \log(litter)$\
$median(log(brainwt)|x) = log(median(brainwt)|x)$\
$median(brainwt|x) = e^{0.8548} * (bodywt^{0.5751}) * (gest^{0.4179}) / (litter^{0.3101})$\
$median(brainwt|(2bodywt)) = e^{0.8548} * 2^{0.5751} * bodywt^{0.5751}$\
Looking at the last line above, the multiplicative change in brain weight given a change in body weight is the $2^{0.5751}$ value.


-------------------------------------

## Problem 5: Perch weights 
Consider estimating the weight (g) of a perch (fish) given its width (cm) and length (cm). The estimated mean weight given width and length is given by the function
$$
\hat{\mu}(\textrm{Weight} \mid \textrm{Width, Length})  = 113.9349 - 3.4827\textrm{Length} - 94.6309\textrm{Width} + 5.2412\textrm{Length} \times \textrm{Width}
$$

### (5a)  
A one cm increase in length has what effect on mean weight?
\
*Answer: *\
A one cm increase in length has a $-3.4827 + width*5.2412$ effect on mean weight holding all other predictors constant.

### (5b)  
For perch that are 6 cm wide, a one cm increase in length has what effect on mean weight?
\
*Answer: *\
For perch that are 6 cm wide, a one cm increase in length has a additive effect of 27.9645 on mean weight.

----------------------------------------------

## Problem 6: Pace of life and heart disease: ch. 9 exercise 14 
Take a look at the data described in ch. 9 exercise 14. The data is in the Sleuth data frame `ex0914`. Answer the questions below about this data set:

### (6a) Draw the scatterplot matrix of the four variables in this data set. Describe how `Heart` is related to the covariates `Bank`, `Walk` and `Talk`
\
*Answer: *\
There is a very loose positive strenth with heart and the other 3 variables. So, as heart increases, bank, walk, and talk also generally slowly increase.

```{r}
head(ex0914)
library(GGally)
ggpairs(ex0914, 
        columns = c("Bank","Walk", "Talk","Heart"), 
        lower = list(continuous = "smooth"))
```

### (6b) Fit the regression of `Heart` on `Bank`, `Walk` and `Talk` and write down the fitted (estimated) mean function. 
\
*Answer: *\
$\mu({heart|bank, walk, talk}) = 3.1787 + 0.4052bank + 0.4516walk - 0.1796talk$

```{r}
lm_heart <- lm(Heart ~ Bank + Walk + Talk, ex0914)
lm_heart
```

### (6c) Interpret (in context!) the effects of each of the three predictors bank, walk, and talk on the response heart.
\
*Answer: *\
Holding the walking speed of pedestrians and talking responses of postal clerks fixed and increasing the average time a sample of bank clerks takes to make change for two $20 bills or to give \$20 bills for change by one unit increases the age adjusted death rates due to heart disease by 0.4052 units.\

Holding the walking speed of pedestrians and the average time a sample of bank clerks takes to make change for two $20 bills or to give \$20 bills for change fixed and increasing talking responses of postal clerks by one unit decreases the age adjusted death rates due to heart disease by 0.1796 units.\

Holding the talking responses of postal clerks and the average time a sample of bank clerks takes to make change for two $20 bills or to give \$20 bills for change fixed and increasing the walking speed of pedestrians by one unit increases the age adjusted death rates due to heart disease by 0.4516 units.\







